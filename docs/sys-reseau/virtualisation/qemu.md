---
description: "MaÃ®triser QEMU comme Ã©mulateur/virtualiseur open-source : bases, architecture, images disque et premiÃ¨res VMs qui sont les fondations de KVM et Proxmox"
icon: lucide/book-open-check
tags: ["QEMU", "VIRTUALISATION", "Ã‰MULATION", "KVM", "LIBVIRT", "INFRASTRUCTURE"]
---

# QEMU - (Ã‰mulateur)

<div
  class="omny-meta"
  data-level="ğŸŸ¡ IntermÃ©diaire & ğŸ”´ AvancÃ©"
  data-version="1.3"
  data-time="60-75 minutes">
</div>

## Introduction aux bases gÃ©nÃ©rales de QEMU

!!! quote "Analogie pÃ©dagogique"
    _Imaginez un **traducteur universel** capable de simuler n'importe quel processeur du monde : vous lui confiez un programme Ã©crit pour un processeur ARM (smartphone), et il le fait tourner sur votre processeur x86 (PC). Mais ce traducteur possÃ¨de aussi un mode **turbo** : quand le programme est dÃ©jÃ  dans la langue native de votre machine, il le laisse s'exÃ©cuter directement Ã  pleine vitesse grÃ¢ce Ã  KVM[^1]. **QEMU fonctionne exactement ainsi** : c'est un Ã©mulateur polyvalent qui peut simuler des dizaines d'architectures diffÃ©rentes, mais qui devient un hyperviseur ultra-performant quand il s'associe au noyau Linux via KVM[^1]._

**QEMU** (Quick Emulator) constitue un **Ã©mulateur et virtualiseur open-source** capable de simuler une machine complÃ¨te : _processeur_, _mÃ©moire_, _pÃ©riphÃ©riques_, _rÃ©seau_. CrÃ©Ã© en 2003 par Fabrice Bellard, QEMU est devenu la **pierre angulaire** ou **brique fondamentale** de l'Ã©cosystÃ¨me de virtualisation Linux, servant de fondation Ã  KVM et libvirt, et par extension Ã  Proxmox VE, OpenStack, etc.

Dans un contexte oÃ¹ les infrastructures modernes reposent sur la virtualisation pour _l'isolation_, _la scalabilitÃ©_ et _la rÃ©silience_, comprendre QEMU permet de maÃ®triser les **fondations techniques** sur lesquelles s'appuient les plateformes de production. Pour un professionnel de la cybersÃ©curitÃ©, QEMU offre Ã©galement un environnement idÃ©al pour l'**analyse de malware**, le **reverse engineering** et la crÃ©ation de **laboratoires d'attaque isolÃ©s**.

!!! info "Pourquoi maÃ®triser QEMU ?"
    - **Fondation de l'Ã©cosystÃ¨me Linux** :  
      _KVM, libvirt, Proxmox, OpenStack utilisent tous QEMU comme backend d'exÃ©cution._
    
    - **Ã‰mulation multi-architecture** :  
      _Tester du code ARM sur x86, analyser des firmwares embarquÃ©s, dÃ©velopper pour IoT._
    
    - **FlexibilitÃ© maximale** :  
      _ContrÃ´le fin sur chaque aspect de la VM : CPU, mÃ©moire, rÃ©seau, stockage._
    
    - **Snapshots et introspection** :  
      _Capturer l'Ã©tat d'une VM, analyser la mÃ©moire, debugger des systÃ¨mes._

---

## Pour repartir des bases

!!! quote "PrÃ©-requis recommandÃ©"
    Avant tout, pour comprendre oÃ¹ se situe QEMU dans l'Ã©cosystÃ¨me global de la virtualisation
    (_Type 1 / Type 2_, _VirtualBox_, _VMware_, _Hyper-V_, _WSL_, _KVM_, _libvirt_, _Proxmox_),
    commence par la page **â€œPanorama de la virtualisationâ€**.

Si vous dÃ©couvrez QEMU, quatre points fondamentaux sont Ã  retenir :

### 1. Deux modes : Ã‰mulation vs Virtualisation

QEMU opÃ¨re selon **deux modes distincts** qui rÃ©pondent Ã  des besoins diffÃ©rents :

- **Mode Ã©mulation (TCG â€“ Tiny Code Generator)**  
  _QEMU traduit dynamiquement les instructions de lâ€™architecture invitÃ©e vers celles de lâ€™architecture hÃ´te.  
  Tu peux par exemple exÃ©cuter du code ARM sur un CPU x86._

!!! quote "Câ€™est **lent mais universel**"

```mermaid
---
title: "Mode Ã‰MULATION (TCG) â€“ universel mais plus lent"
config:
  theme: "base"
---
graph TB
  subgraph "Ã‰mulation (TCG)"
    E1["Code invitÃ©<br/>(ex: binaire ARM)"]
    E2["TCG<br/>(traduction dynamique des instructions)"]
    E3["CPU hÃ´te<br/>(ex: x86_64)"]
    E1 --> E2 --> E3
  end
```
<small>_En mode Ã©mulation TCG, QEMU traduit les instructions dâ€™une architecture invitÃ©e (ex : ARM) vers lâ€™architecture de lâ€™hÃ´te (ex : x86_64). Câ€™est trÃ¨s flexible (toutes architectures), mais sensiblement plus lent que lâ€™exÃ©cution native._</small>

- **Mode virtualisation (avec KVM)**  
  _QEMU dÃ©lÃ¨gue lâ€™exÃ©cution des instructions CPU au noyau Linux via **KVM**[^1]. Le code invitÃ© sâ€™exÃ©cute **nativement sur le CPU physique**, avec trÃ¨s peu de surcoÃ»t, mais uniquement si `lâ€™architecture invitÃ©e = architecture hÃ´te` (x86 sur x86, etc.) et que le CPU dispose de VT-x / AMD-V.[^2]_

!!! tip "Performances proches du bare-metal"

```mermaid
---
title: "Mode VIRTUALISATION (KVM) â€“ exÃ©cution quasi bare-metal"
config:
  theme: "base"
---
graph TB
  subgraph "Virtualisation avec KVM"
    V1["Code invitÃ©<br/>(mÃªme archi que l'hÃ´te, ex: x86_64)"]
    V2["KVM<br/>(hyperviseur noyau Linux)"]
    V3["CPU hÃ´te<br/>(ex: x86_64 avec<br/>VT-x/AMD-V)"]
    V1 --> V2 --> V3
  end
```
<small>_En mode virtualisation KVM, les instructions invitÃ©es sâ€™exÃ©cutent presque directement sur le CPU physique. Les performances sont proches du bare-metal, mais cela ne fonctionne que si lâ€™architecture invitÃ©e est identique Ã  celle de lâ€™hÃ´te, avec support VT-x/AMD-V._</small>

!!! note "Ã€ retenir"
    Lâ€™**Ã©mulation** te permet de tester des **architectures exotiques** (ARM, MIPS, RISC-Vâ€¦) au prix de performances faibles.
    La **virtualisation avec KVM** te donne des performances **proches du bare-metal**, mais uniquement pour la mÃªme architecture et avec support matÃ©riel.

??? abstract "Approfondir : fonctionnement interne de TCG"

    **TCG** (*Tiny Code Generator*) est le moteur dâ€™**Ã©mulation pure** de QEMU : il joue le rÃ´le de compilateur JIT qui traduit Ã  la volÃ©e les instructions de lâ€™architecture invitÃ©e vers celles de lâ€™architecture hÃ´te.

    SchÃ©matiquement, pour chaque portion de code invitÃ© :

    1. **Fetch** â€“ QEMU lit les instructions de la VM (ex : ARM).
    2. **Decode** â€“ Elles sont converties dans une reprÃ©sentation intermÃ©diaire.
    3. **Translate** â€“ Cette IR est compilÃ©e en instructions natives pour le CPU hÃ´te.
    4. **Cache** â€“ Le bloc traduit est mis en cache pour Ãªtre rÃ©utilisÃ©.
    5. **Execute** â€“ Le CPU exÃ©cute directement ce bloc natif.

    **Forces :**  

    - [x] fonctionne sans VT-x/AMD-V,  
    - [x] supporte quasiment *toutes* les architectures (ARM, MIPS, RISC-V, â€¦),  
    - [x] offre une trÃ¨s bonne introspection de lâ€™Ã©tat CPU.

    **Limites :**  

    - [ ] **beaucoup plus lent** que lâ€™exÃ©cution native (facteur 10â€“100x),  
    - [ ] consomme fortement le CPU hÃ´te sur des charges longues.

    En rÃ©sumÃ© : **TCG = flexibilitÃ© maximale, performances minimales**, idÃ©al pour le *cross-architecture*, le firmware embarquÃ© et le debug bas niveau.


??? abstract "Approfondir : rÃ´le exact de KVM et du noyau"

    **KVM** (*Kernel-based Virtual Machine*) transforme le noyau Linux en **hyperviseur de type 1** : les instructions de la VM sâ€™exÃ©cutent directement sur le CPU physique grÃ¢ce aux extensions VT-x/AMD-V, tandis que QEMU se concentre sur lâ€™**Ã©mulation des pÃ©riphÃ©riques** (disque, rÃ©seau, USB, affichageâ€¦).

    Vue simplifiÃ©e de la pile :

    ```text
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚          Guest OS (VM)                 â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚        QEMU (devices virtuels)         â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚        Module KVM (kvm.ko)             â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚            Noyau Linux                 â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚   MatÃ©riel avec VT-x / AMD-V activÃ©    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    ```

    **RÃ´le de chacun :**

    - **KVM** gÃ¨re lâ€™exÃ©cution CPU et la mÃ©moire invitÃ©e en sâ€™appuyant sur le matÃ©riel.  
    - **QEMU** intercepte les accÃ¨s I/O, Ã©mule les pÃ©riphÃ©riques et pilote la VM.  
    - Le **noyau Linux** fournit lâ€™isolation, les cgroups, le scheduling, etc.

    Avec KVM activÃ©, on obtient des performances **95â€“99 % du bare-metal**, Ã  condition que lâ€™architecture invitÃ©e soit identique Ã  celle de lâ€™hÃ´te (x86 sur x86, ARM sur ARM) et que les modules `kvm`, `kvm_intel` ou `kvm_amd` soient correctement chargÃ©s.

---

### 2. QEMU simule une machine complÃ¨te

Contrairement aux conteneurs qui partagent le noyau de lâ€™hÃ´te, QEMU Ã©mule **l'intÃ©gralitÃ© du matÃ©riel** ce qui peut simplement se traduire par **toute la machine** :

* **CPU** : x86, x86_64, ARM, AARCH64, MIPS, RISC-V, PowerPC, SPARC, etc.
* **MÃ©moire** : RAM configurable, Ã©ventuellement optimisÃ©e via **huge pages**.[^3]
* **Stockage** : disques virtuels (qcow2, raw, vmdk, vdiâ€¦), CD-ROM, USB.
* **RÃ©seau** : cartes rÃ©seau virtuelles (e1000, virtio-netâ€¦), NAT[^4], bridge, tap.
* **PÃ©riphÃ©riques** : GPU virtuel, audio, contrÃ´leur USB, TPM virtuel.
* **Firmware** : BIOS (SeaBIOS), UEFI (OVMF), Coreboot.

!!! note "Zoom : vue interne simplifiÃ©e de QEMU"

```mermaid
---
title: "Vue interne simplifiÃ©e de QEMU"
config:
  theme: "base"
---
graph TB
    subgraph QEMU["QEMU (processus unique cÃ´tÃ© hÃ´te)"]
        CPU["Ã‰mulation CPU<br/>(TCG ou KVM)"]
        MEM["Gestion mÃ©moire<br/>(RAM invitÃ©e, MMIO)"]
        DEV["Ã‰mulation des pÃ©riphÃ©riques<br/>(disque, rÃ©seau, USB, affichage)"]
        BACK["Backends cÃ´tÃ© hÃ´te<br/>(images disque, TAP/bridge, VNC/SPICE)"]
    end

    CPU --> MEM
    MEM --> DEV
    DEV --> BACK

```
<small>Cette vue montre comment QEMU sÃ©pare lâ€™Ã©mulation CPU (TCG/KVM), la mÃ©moire invitÃ©e, lâ€™Ã©mulation des pÃ©riphÃ©riques et les backends de stockage/rÃ©seau.</small>

!!! quote "Cela permet de **reproduire des scÃ©narios trÃ¨s proches dâ€™un vrai serveur** (ou dâ€™un Ã©quipement embarquÃ©) sans disposer du matÃ©riel physique."

---

### 3. QEMU dans lâ€™Ã©cosystÃ¨me de virtualisation

QEMU ne fonctionne pas seul en production. Il s'intÃ¨gre dans une **stack de virtualisation** qui comprends :

* **libvirt** : API de gestion et dâ€™orchestration.
* **KVM** : module noyau transformant Linux en hyperviseur de type 1.[^5]
* **Interfaces** : Proxmox VE, virt-manager, Cockpit, OpenStackâ€¦

=== "Niveau 1 : Interfaces utilisateur"

    **Vue 1 â€” Les interfaces utilisateur (le â€œhautâ€ de la stack)**

    ```mermaid
    ---
    title: "Niveau 1 : Interfaces utilisateur"
    config:
      theme: "base"
    ---
    graph TB
        Frontend[/"Frontend"/]
        subgraph INTERFACE["Interfaces utilisateur"]
          UI1["Proxmox VE<br/>(gestion cluster, GUI web)"]
          UI2["virt-manager<br/>(administration locale en GUI)"]
          UI3["Cockpit<br/>(GUI serveur + virtualisation)"]
        end
        
        subgraph ORCHESTRATION["Couche de gestion"]
          O1["libvirt<br/>(API centrale)"]
        end

        UI1 --> O1
        UI2 --> O1
        UI3 --> O1
        INTERFACE -.aussi appelÃ©.- Frontend
    ```
    <small>_Les interfaces comme Proxmox, virt-manager ou Cockpit ne parlent jamais directement Ã  QEMU ou KVM. Elles sâ€™appuient toutes sur libvirt, qui joue le rÃ´le de couche dâ€™orchestration et dâ€™API unifiÃ©e._</small>

=== "Niveau 2 : libvirt"

    ```mermaid
    ---
    title: "Niveau 2 : libvirt â€” API et gestion des VM"
    config:
      theme: "base"
    ---
    graph LR
        subgraph ORCHESTRATION["Couche de gestion"]
            O1["libvirt<br/>(API + daemon libvirtd)"]
            O2["virsh CLI<br/>(console d'administration libvirt)"]
        end
        
        Backend[/"Backend"/]
        subgraph EXECUTION["Moteur d'exÃ©cution"]
            Q["QEMU<br/>(Ã©mulation + pÃ©riphÃ©riques)"]
        end

        O2 --> O1
        O1 --> Q
        Q -.Aussi appelÃ©.- Backend

    ```
    <small>_libvirt fournit une API stable et universelle pour crÃ©er, dÃ©marrer, arrÃªter ou configurer une VM. virsh est la CLI officielle qui contrÃ´le ce daemon. libvirt ne crÃ©e pas les VMs lui-mÃªme : il invoque QEMU comme moteur dâ€™exÃ©cution._</small>

=== "Niveau 3 : QEMU & KVM"

    ```mermaid
    ---
    title: "Niveau 3 : QEMU & KVM â€” ExÃ©cution et accÃ©lÃ©ration"
    config:
      theme: "base"
    ---
    graph LR
        subgraph EXECUTION["Moteur d'exÃ©cution (VMs)"]
            Q["QEMU<br/>(Ã©mulation CPU + pÃ©riphÃ©riques virtuels)"]
            K["KVM<br/>(accÃ©lÃ©ration matÃ©rielle)"]
        end
        
        subgraph KERNEL["Noyau Linux de l'hÃ´te"]
            L["kvm.ko<br/>(module hyperviseur gÃ©nÃ©rique)"]
            L2["kvm_intel / kvm_amd<br/>(spÃ©cifique au CPU)"]
        end

        Q --> K
        K --> L
        L --> L2
    ```
    <small>_QEMU gÃ¨re lâ€™Ã©mulation et les pÃ©riphÃ©riques, mais dÃ©lÃ¨gue lâ€™exÃ©cution CPU au module KVM du noyau Linux. KVM sâ€™appuie sur des extensions matÃ©rielles (VT-x/AMD-V) via kvm_intel ou kvm_amd pour exÃ©cuter le code invitÃ© quasi nativement._</small>

=== "Vue d'ensemble"

    ```mermaid
    ---
    title: "Vue d'ensemble : Stack complÃ¨te de virtualisation Linux"
    config:
      theme: "base"
    ---
    graph LR
        subgraph INTERFACE["Nv1 : Interfaces utilisateur"]
            direction TB
            UI1["Proxmox VE<br/>(cluster, GUI web)"]
            UI2["virt-manager<br/>(GUI poste admin)"]
            UI3["Cockpit<br/>(GUI serveur)"]
        end
        
        subgraph ORCHESTRATION["Nv2 : Couche de gestion"]
            direction LR
            O1["libvirt<br/>(API + daemon libvirtd)"]
            O2["virsh CLI<br/>(ligne de commande libvirt)"]
        end
        
        subgraph EXECUTION["Nv3 : ExÃ©cution des VMs"]
            direction LR
            Q["QEMU<br/>(moteur + pÃ©riphÃ©riques)"]
            K["KVM<br/>(accÃ©lÃ©ration CPU)"]
        end
        
        subgraph KERNEL["Nv4 : Noyau Linux"]
            direction LR
            L["kvm.ko<br/>(module KVM)"]
            L2["kvm_intel / kvm_amd<br/>(support matÃ©riel)"]
        end
        
        UI1 --> O1
        UI2 --> O1
        UI3 --> O1
        O2 --> O1
        O1 --> Q
        Q --> K
        K --> L
        L --> L2
    ```
    <small>_Les interfaces (Proxmox, virt-manager, Cockpit) â†’ sâ€™appuient sur libvirt â†’ qui invoque QEMU â†’ qui sâ€™appuie sur KVM â†’ qui exploite les modules du noyau. Câ€™est la chaÃ®ne complÃ¨te dâ€™un environnement de virtualisation Linux moderne._</small>

!!! note "Ã€ retenir"
    QEMU est le **moteur dâ€™exÃ©cution** des VMs. **libvirt** fournit la **couche de gestion** (XML, virsh, API) quant aux outils comme **Proxmox** ou **virt-manager** sont essentiellement des **frontends** par-dessus libvirt.

---

### 4. Cas dâ€™usage typiques

Quelques cas dâ€™usage frÃ©quents :

- [x] Monter une **infrastructure de virtualisation KVM/libvirt** locale.
- [x] Tester un **OS ou une distrib** sans toucher Ã  la machine physique.
- [x] Faire du **dÃ©veloppement cross-plateforme** (par exemple, ARM sur x86) via Ã©mulation.
- [x] Monter un **environnement de test jetable** pour scripts, configurations, dÃ©ploiements.
- [x] Tests **multi-plateforme** pour valider un logiciel sur diffÃ©rentes architectures CPU.
- [x] Mettre en place des cas dâ€™usage plus **â€œcyberâ€** (**malware**, **IoT**, **pentest**) 
- [ ] _et bien d'autres encore_.

---

## PrÃ©-requis : vÃ©rifier le support KVM

### Fiche 1 â€“ VÃ©rifier la virtualisation matÃ©rielle

Avant mÃªme de travailler avec QEMU et KVM, il est indispensable de sâ€™assurer que la machine hÃ´te peut exploiter la virtualisation matÃ©rielle. Cette fiche permet de **vÃ©rifier rapidement la prÃ©sence des extensions CPU** (_VT-x/AMD-V_), **lâ€™Ã©tat des modules KVM dans le noyau Linux** et **les permissions nÃ©cessaires pour accÃ©der au device** `/dev/kvm`.

!!! info "Sans ces prÃ©requis, QEMU fonctionne uniquement en mode Â« Ã©mulation pure Â», ce qui limite fortement les performances et lâ€™usage en production."

```bash
# VÃ©rifier si le CPU supporte la virtualisation matÃ©rielle
# Intel : drapeau VMX ; AMD : drapeau SVM
grep -E "(vmx|svm)" /proc/cpuinfo | head -5
```

!!! warning "Si Ã  ce stade, la commande ne renvoie rien, le CPU **ne supporte pas** VT-x/AMD-V[^2] ou c'est que la fonctionnalitÃ© est dÃ©sactivÃ©e dans le BIOS/UEFI."

```bash
# VÃ©rifier la prÃ©sence des modules KVM
lsmod | grep kvm

# Exemple de rÃ©sultat attendu (Intel) :
# kvm_intel             368640  0
# kvm                  1028096  1 kvm_intel

# RÃ©sultat attendu (AMD) :
# kvm_amd               155648  0
# kvm                  1028096  1 kvm_amd
```

```bash
# Charger les modules si nÃ©cessaire
sudo modprobe kvm
sudo modprobe kvm_intel    # ou kvm_amd
```

```bash
# VÃ©rifier lâ€™accÃ¨s au device KVM
ls -la /dev/kvm
# crw-rw---- 1 root kvm 10, 232 ... /dev/kvm

# Ajouter ton utilisateur au groupe kvm (Ã©vite sudo)
sudo usermod -aG kvm "$USER"
# (dÃ©connexion / reconnexion requise)
```

!!! note "Ã€ retenir"
    Sans `/dev/kvm` accessible, tu restes en **Ã©mulation pure (TCG)** :  
    _Ã§a marche, mais câ€™est trÃ¨s lent. Pour de la **virtualisation performante**, KVM est indispensable._

---

## Installation de QEMU + libvirt

### Fiche 2 â€“ Installation sur diffÃ©rentes distrib'

Cette fiche propose une installation propre et standardisÃ©e de **QEMU**, **KVM**, **libvirt** et **virt-manager** selon les principales distributions Linux. Elle fournit les commandes essentielles pour disposer dâ€™un environnement complet : _moteur QEMU_, _accÃ©lÃ©ration KVM_, _API libvirt_, _outils de crÃ©ation de VM_ et _interface graphique_.

!!! info "Lâ€™objectif est dâ€™obtenir une base stable et uniforme pour la suite des manipulations."

=== ":fontawesome-brands-debian:  Debian / :fontawesome-brands-ubuntu: Ubuntu"

    ```bash
    # Mise Ã  jour des paquets
    sudo apt update && sudo apt upgrade -y

    # Installation QEMU + libvirt + interface graphique
    sudo apt install -y \
        qemu-system-x86 \
        qemu-system-arm \
        qemu-system-misc \
        qemu-utils \
        qemu-block-extra \
        ovmf \
        libvirt-daemon-system \
        libvirt-clients \
        virtinst \
        virt-manager \
        bridge-utils

    # Activer libvirt
    sudo systemctl enable --now libvirtd

    # Ajouter ton utilisateur aux groupes
    sudo usermod -aG libvirt,kvm "$USER"
    ```

    !!! info "Explication des outils"
        - **qemu-system-x86** : _Ã‰mulation x86/x86_64_
        - **qemu-system-arm** : _Ã‰mulation ARM_
        - **qemu-system-misc** : _Autres architectures_
        - **qemu-utils** : _qemu-img, qemu-nbd..._
        - **qemu-block-extra** : _Formats additionnels_
        - **ovmf** : _Firmware UEFI_
        - **libvirt-daemon-system** : _Service libvirtd_
        - **libvirt-clients** : _virsh_
        - **virtinst** : _virt-install_
        - **virt-manager** : _Interface graphique_
        - **bridge-utils** : _Outils bridge rÃ©seau_

=== "RHEL / Rocky / AlmaLinux"

    ```bash
    # Installation des groupes de virtualisation
    sudo dnf groupinstall -y "Virtualization Host" "Virtualization Client"
    
    # Ou installation manuelle des paquets
    sudo dnf install -y \
        qemu-kvm \
        qemu-img \
        libvirt \
        libvirt-client \
        virt-install \
        virt-manager \
        edk2-ovmf
    
    # Activer et dÃ©marrer libvirt
    sudo systemctl enable --now libvirtd
    
    # Ajouter l'utilisateur aux groupes
    sudo usermod -aG libvirt,kvm $USER
    
    # Ouvrir le pare-feu pour VNC (optionnel)
    sudo firewall-cmd --add-service=vnc-server --permanent
    sudo firewall-cmd --reload
    ```

    !!! info "Explication des outils"
        - **qemu-kvm** : _QEMU avec support KVM_
        - **qemu-img** : _Manipulation d'images disque_
        - **libvirt** : _API de gestion_
        - **libvirt-client** : _CLI virsh_
        - **virt-install** : _CrÃ©ation de VMs_
        - **virt-manager** : _Interface graphique_
        - **edk2-ovmf** : _Firmware UEFI_

=== "Arch Linux"

    ```bash
    # Installation des paquets
    sudo pacman -S \
        qemu-full \                 # QEMU complet (toutes architectures)
        libvirt \                   # API de gestion
        virt-manager \              # Interface graphique
        virt-viewer \               # Affichage VNC/SPICE
        dnsmasq \                   # DHCP/DNS pour rÃ©seau virtuel
        bridge-utils \              # Configuration bridge
        edk2-ovmf                   # Firmware UEFI
    
    # Activer les services
    sudo systemctl enable --now libvirtd
    
    # Configurer les groupes
    sudo usermod -aG libvirt,kvm $USER
    ```

    !!! info "Explication des outils"
        - **qemu-full** : _QEMU complet (toutes architectures)_
        - **libvirt** : _API de gestion_
        - **virt-manager** : _Interface graphique_
        - **virt-viewer** : _Affichage VNC/SPICE_
        - **dnsmasq** : _DHCP/DNS pour rÃ©seau virtuel_
        - **bridge-utils** : _Configuration bridge_
        - **edk2-ovmf** : _Firmware UEFI_

### ContrÃ´les & Configuration post-installation

Il ne faut surtout pas omettre la phase de contrÃ´le pour savoir si tout s'est installÃ© correctement.

```bash
# VÃ©rifier que libvirt fonctionne
sudo systemctl status libvirtd

# Lister les rÃ©seaux virtuels disponibles
virsh net-list --all

# DÃ©marrer le rÃ©seau par dÃ©faut (NAT)
virsh net-start default
virsh net-autostart default

# VÃ©rifier la connexion QEMU
virsh -c qemu:///system list --all

# CrÃ©er un rÃ©pertoire pour les images disque
sudo mkdir -p /var/lib/libvirt/images
sudo chown root:libvirt /var/lib/libvirt/images
sudo chmod 775 /var/lib/libvirt/images
```

---

## Comprendre les formats dâ€™images disque

### Comparatif rapide

| Format    | Extension     |Avantages (âœ…) | InconvÃ©nients (âŒ)                | Cas dâ€™usage principal       |
| --------- | ------------- | ------------------------------------------------------ | ----------------------------- | --------------------------- |
| **qcow2** | `.qcow2`      | Snapshots, compression, thin provisioning[^6], chiffrement | LÃ©gÃ¨rement plus lent que raw  | Production, dÃ©veloppement, labs   |
| **raw**   | `.img` `.raw` | Performances maximales, format simple                  | Taille fixe, pas de snapshots | I/O intensives, benchmark   |
| **vmdk**  | `.vmdk`       | CompatibilitÃ© VMware                                   | Moins flexible sous QEMU      | Migration depuis VMware     |
| **vdi**   | `.vdi`        | CompatibilitÃ© VirtualBox                               | Peu dâ€™intÃ©rÃªt en natif QEMU   | Migration depuis VirtualBox |
| **vhdx**  | `.vhdx`       | CompatibilitÃ© Hyper-V                                  | Support plus limitÃ©           | Migration depuis Hyper-V    |

!!! success "qcow2 grand vainqueur"
    Dans 90 % des cas sur une infra QEMU/KVM moderne, **qcow2** est le bon choix : 

    - snapshots
    - compression
    - thin provisioning[^6]
    - backing files

---

## Fiches qemu-img (micro-recettes)

Cette section regroupe une sÃ©rie de **micro-fiches autour de `qemu-img`** : _crÃ©ation dâ€™images_, _inspection_, _conversion_, _redimensionnement_ et _gestion avancÃ©e des snapshots_ / _backing files_[^7].  

> Lâ€™idÃ©e est dâ€™avoir **des commandes courtes, rÃ©utilisables** et faciles Ã  intÃ©grer dans des scripts ou playbooks dâ€™admin / cyber.

### Fiche 3 â€“ CrÃ©er une image disque

CrÃ©er une image disque est **la premiÃ¨re Ã©tape avant lâ€™installation** ou **lâ€™import dâ€™un systÃ¨me invitÃ©**. Cette fiche prÃ©sente la crÃ©ation dâ€™images aux formats **RAW** et **QCOW2**, en prÃ©cisant _les diffÃ©rences pratiques entre prÃ©allocation, allocation dynamique et optimisation performance_.

!!! info "Elle constitue la fondation de toute VM, que ce soit pour un usage classique, un lab cyber ou une infrastructure KVM/libvirt."

```bash
# CrÃ©er une image "qcow2" de 50 Go (thin provisioning)
# L'espace n'est allouÃ© que lors de l'Ã©criture soit Ã  la demande
qemu-img create -f qcow2 debian.qcow2 50G
```

```bash
# CrÃ©er une image "qcow2" avec prÃ©allocation (meilleures performances)
# L'espace est rÃ©servÃ© immÃ©diatement sur le disque
qemu-img create -f qcow2 -o preallocation=full debian.qcow2 50G
```

```bash
# Image raw (taille fixe, perfs maximales)
qemu-img create -f raw disk.raw 50G
```

---

### Fiche 4 â€“ Inspecter et vÃ©rifier une image

**Comprendre lâ€™Ã©tat dâ€™une image disque** est essentiel pour **le diagnostic**, **la maintenance** ou **lâ€™investigation**. Cette fiche explique comment inspecter une image (_format_, _taille virtuelle_/_rÃ©elle_, _compression_, _chaÃ®nes de backing files_[^7]) et _comment en vÃ©rifier lâ€™intÃ©gritÃ©_.

!!! info "Elle est particuliÃ¨rement utile lors de migrations de VM, dâ€™opÃ©rations de sauvegarde ou dâ€™analyse forensic."

```bash
# Obtenir des informations dÃ©taillÃ©es d'une image
qemu-img info debian.qcow2

# RÃ©sultat type :
# image: debian.qcow2
# file format: qcow2
# virtual size: 50 GiB (53687091200 bytes)
# disk size: 1.2 GiB                        â† Taille rÃ©elle sur disque
# cluster_size: 65536
# Format specific information:
#     compat: 1.1
#     compression type: zlib
#     lazy refcounts: false
#     refcount bits: 16
#     corrupt: false
#     extended l2: false
```

```bash
# VÃ©rifier lâ€™intÃ©gritÃ© basique de lâ€™image
qemu-img check debian.qcow2
```

---

### Fiche 5 â€“ Convertir entre formats

Les infrastructures ne reposent pas toutes sur les mÃªmes hyperviseurs, et il est frÃ©quent de devoir convertir des images entre formats (**VMDK**, **RAW**, **QCOW2**, **VDI**). Cette fiche dÃ©taille le processus de conversion avec qemu-img, tout en expliquant **quand** et **pourquoi** passer dâ€™un format Ã  un autre : _migration depuis VMware_/_VirtualBox_, _optimisation de stockage_, _compatibilitÃ© avec KVM_/_libvirt_ ou _Proxmox_.

```bash
# Convertir RAW vers QCOW2
qemu-img convert -f raw -O qcow2 disk.raw disk.qcow2
```

```bash
# Convertir VMDK (VMware) vers QCOW2
qemu-img convert -f vmdk -O qcow2 vm.vmdk vm.qcow2
```

```bash
# Conversion avec compression (rÃ©duit la taille)
qemu-img convert -c -f raw -O qcow2 disk.raw disk-compressed.qcow2
```

---

### Fiche 6 â€“ Redimensionner une image

Lorsquâ€™une VM nÃ©cessite plus dâ€™espace disque (_ou exceptionnellement moins_), **il faut ajuster la taille de lâ€™image virtuelle avant dâ€™intervenir dans le systÃ¨me invitÃ©**. Cette fiche prÃ©sente **les bonnes pratiques** et **les risques**, en particulier lors de la rÃ©duction dâ€™une image, qui exige une manipulation rigoureuse des partitions internes.

!!! info "Elle clarifie la diffÃ©rence entre modifier la taille virtuelle et ajuster le filesystem dans la VM."

```bash
# Augmenter la taille virtuelle de 20 Go
qemu-img resize debian.qcow2 +20G
```

```bash
# Fixer la taille virtuelle Ã  100 Go
qemu-img resize debian.qcow2 100G
```

```bash
# RÃ©duire une image (dangereux si les partitions ne sont pas rÃ©duites avant)
qemu-img resize --shrink debian.qcow2 30G
```

> En pratique : **agrandir** nâ€™est pas un problÃ¨me si tu agrandis ensuite la partition dans la VM.  
> **RÃ©duire** une image est risquÃ© si le filesystem nâ€™a pas Ã©tÃ© rÃ©duit proprement dans lâ€™invitÃ©.

!!! danger "**ATTENTION**, nous insistons sur le fait que **rÃ©duire une image** peut **causer une perte de donnÃ©es**, il faut d'abord **rÃ©duire les partitions** Ã  l'intÃ©rieur de la VM, c'est un impÃ©ratif majeur."

---

### Fiche 7 â€“ Snapshots internes et backing files

**Les snapshots** et **les overlays QCOW2** sont au cÅ“ur des workflows modernes : _labs cyber_, _environnements jetables_, _tests reproductibles_, _golden images_. Cette fiche dÃ©taille lâ€™utilisation des snapshots internes, mais aussi la crÃ©ation et la gestion des â€œbacking filesâ€[^7] (images diffÃ©rentielles). 

!!! info "Elle montre comment isoler les changements, restaurer rapidement un Ã©tat antÃ©rieur et construire des chaÃ®nes dâ€™images efficaces pour le dÃ©veloppement et la cybersÃ©curitÃ©."

!!! quote "**qcow2** est le format qui supporte nativement les snapshots internes. Les autres formats peuvent bÃ©nÃ©ficier de snapshots via des overlays ou des mÃ©canismes externes (_libvirt_, _LVM_â€¦)."

```bash
# CrÃ©er un snapshot interne (qcow2)
qemu-img snapshot -c "avant-maj" debian.qcow2

# Lister les snapshots
qemu-img snapshot -l debian.qcow2

# Restaurer un snapshot
qemu-img snapshot -a "avant-maj" debian.qcow2

# Supprimer un snapshot
qemu-img snapshot -d "avant-mise-a-jour" disk.qcow2
```

---

### **Bonus â€“ Images diffÃ©rentielles / Backing Files**

Les images diffÃ©rentielles permettent dâ€™utiliser une **image de base propre** (*golden image*) tout en stockant les modifications dans un fichier sÃ©parÃ© appelÃ© **overlay**. Cette technique Ã©vite de dupliquer des disques entiers, rÃ©duit drastiquement lâ€™espace consommÃ© et simplifie les scÃ©narios de test ou de formation.

GrÃ¢ce aux **backing files**[^7], on peut multiplier les environnements dÃ©rivÃ©s, revenir rapidement Ã  un Ã©tat initial, fusionner les changements ou reconstruire une chaÃ®ne complÃ¨te dâ€™images.

!!! info "Ce mÃ©canisme est particuliÃ¨rement utile pour les labs, les environnements jetables et toutes les situations oÃ¹ lâ€™on souhaite *expÃ©rimenter sans jamais altÃ©rer lâ€™image dâ€™origine*."

```bash
# CrÃ©er un overlay basÃ© sur une image de base
qemu-img create -f qcow2 -b base.qcow2 -F qcow2 overlay.qcow2

# Afficher la chaÃ®ne de backing files
qemu-img info --backing-chain overlay.qcow2

# Fusionner un overlay avec sa base (commit)
qemu-img commit overlay.qcow2

# Rebase : changer l'image de base
qemu-img rebase -b new-base.qcow2 -F qcow2 overlay.qcow2
```

!!! note "Ã€ retenir"
    Les **overlays** permettent de garder une **image de base propre** (golden image) et de stocker les modifications dans des fichiers sÃ©parÃ©s. _Câ€™est une base pour les labs, mais aussi pour certains scÃ©narios de prod._

---

## Comprendre la structure d'une cmd QEMU

### Signature d'une commande

```bash
# Structure gÃ©nÃ©rale d'une commande QEMU
qemu-system-<arch> [options machine] [options CPU] [options mÃ©moire] \
                   [options disque] [options rÃ©seau] [options affichage] \
                   [options firmware] [options diverses]
```

### Options Machine, CPU & MÃ©moire

=== "Options : Machine"

    Les options _machine_ dÃ©finissent la **plateforme matÃ©rielle simulÃ©e** par QEMU : _chipset_, _contrÃ´leurs PCIe_, _compatibilitÃ© avec le firmware_, _support IOMMU_ et _comportement gÃ©nÃ©ral du matÃ©riel virtuel_. Le choix entre un modÃ¨le classique comme `pc` et un modÃ¨le moderne comme `q35` influence directement les performances, la compatibilitÃ© des pÃ©riphÃ©riques Virtio et la maniÃ¨re dont lâ€™invitÃ© interagit avec lâ€™hÃ´te.
    
    !!! info "Câ€™est ici que se dÃ©cide lâ€™Ã©quilibre entre compatibilitÃ© maximale et performances optimales."

    ```bash
    # Lister les machines disponibles
    qemu-system-x86_64 -machine help

    # Machine par dÃ©faut (pc = i440fx, ancienne mais compatible)
    -machine pc
    
    # Machine moderne (q35, recommandÃ©e pour les nouvelles VMs)
    # Supporte PCIe, IOMMU, meilleures performances
    -machine q35
    
    # Activer l'accÃ©lÃ©ration KVM
    -machine q35,accel=kvm
    ```
    
=== "Options : CPU"

    Les options CPU dÃ©terminent la **modÃ©lisation du processeur virtuel** : _instructions disponibles_, _nombre de vCPUs_, _organisation en sockets_/_cores_/_threads_ et_ exposition des capacitÃ©s matÃ©rielles de lâ€™hÃ´te_.  
    
    En mode KVM, utiliser `-cpu host` permet dâ€™exposer quasi intÃ©gralement le CPU rÃ©el, garantissant des performances proches du bare-metal.
    
    !!! info "Cette section conditionne autant les performances que la compatibilitÃ© logicielle du systÃ¨me invitÃ©."

    ```bash
    # Lister les CPUs disponibles
    qemu-system-x86_64 -cpu help

    # CPU gÃ©nÃ©rique (compatible, lent)
    -cpu qemu64
    
    # CPU hÃ´te (expose le CPU rÃ©el, meilleures performances avec KVM)
    -cpu host
    
    # CPU spÃ©cifique (Ã©mulation prÃ©cise)
    -cpu Skylake-Server-v5
    
    # Nombre de vCPUs (virtual CPU)
    -smp 4
    
    # Configuration avancÃ©e : 4 vCPUs, 2 sockets, 2 cores par socket
    -smp 4,sockets=2,cores=2,threads=1
    ```

=== "Options : MÃ©moire"

    Ces options contrÃ´lent la **quantitÃ©**, **lâ€™organisation** et **le mode de gestion de la mÃ©moire RAM** allouÃ©e Ã  la VM. QEMU permet de dÃ©finir _une taille fixe_, _une mÃ©moire extensible_ (hotplug) ou _des optimisations_ comme les **huge pages**[^3] pour rÃ©duire la surcharge de gestion des pages.
    
    !!! info "Une bonne configuration mÃ©moire amÃ©liore la stabilitÃ©, rÃ©duit la latence et optimise les charges intensives."

    ```bash    
    # MÃ©moire en mÃ©gaoctets
    -m 2048
    
    # MÃ©moire en gigaoctets
    -m 4G
    
    # MÃ©moire avec notation explicite
    -m size=4096M
    
    # MÃ©moire avec slots pour ajout Ã  chaud (hotplug)
    -m 4G,slots=4,maxmem=16G
    ```
    
    **HUGE PAGES (performances)**
    
    ```bash
    # Utiliser des huge pages (2 Mo au lieu de 4 Ko)
    # RÃ©duit la surcharge de gestion mÃ©moire
    -mem-path /dev/hugepages
    
    # Configuration prÃ©alable sur l'hÃ´te :
    # echo 2048 > /proc/sys/vm/nr_hugepages
    # ou dans /etc/sysctl.conf : vm.nr_hugepages = 2048
    ```

### Options Disque, RÃ©seau & Affichage

=== "Options : Disque"

    Les options disque dÃ©finissent la **connexion** et le **comportement des volumes virtuels** : _interface utilisÃ©e_ (**Virtio**, **IDE**, **SCSI**), _format_ (**qcow2**, **raw**), _stratÃ©gies de cache_, _fichier ISO_, _ordre de boot_ et _gestion du CD-ROM_.
    
    !!! info "Le paramÃ©trage de cette section influence fortement les performances I/O, la sÃ©curitÃ© des Ã©critures, et la capacitÃ© Ã  utiliser des fonctionnalitÃ©s avancÃ©es comme les snapshots ou les overlays."

    **Stockage**

    ```bash
    # Disque simple (legacy, dÃ©prÃ©ciÃ© mais fonctionnel)
    -hda disk.qcow2
    
    # Syntaxe moderne avec -drive
    -drive file=disk.qcow2,format=qcow2,if=virtio
    
    # Explication des paramÃ¨tres :
    # file=       : chemin vers l'image disque
    # format=     : format de l'image (qcow2, raw, vmdk...)
    # if=         : interface (virtio, ide, scsi)
    #               virtio = meilleures performances
    #               ide    = compatibilitÃ© maximale
    # cache=      : mode de cache (none, writeback, writethrough)
    #               none          = performances, risque perte donnÃ©es
    #               writeback     = performances avec cache
    #               writethrough  = sÃ©curitÃ©, plus lent
    # aio=        : async I/O (native, threads)
    #               native = meilleures performances (requiert cache=none)
    
    # Configuration optimale pour production
    -drive file=disk.qcow2,format=qcow2,if=virtio,cache=none,aio=native
    ```

    **CD-ROM ET ISO**
    ```bash
    # Attacher un ISO comme CD-ROM
    -cdrom debian-12.iso
    
    # Syntaxe moderne
    -drive file=debian-12.iso,media=cdrom,readonly=on
    ```
    
    **ORDRE DE BOOT**
    ```bash
    # Boot sur CD-ROM en premier
    -boot d
    
    # Boot sur disque dur en premier
    -boot c
    
    # Menu de boot interactif
    -boot menu=on
    
    # Ordre de boot (c=hdd, d=cdrom, n=network)
    -boot order=dc    # ici : cdrom -> hdd
    ```

=== "Options : RÃ©seau"

    Ces options contrÃ´lent la **connexion de la VM au rÃ©seau** : _carte virtuelle utilisÃ©e_, _type de backend_ (**NAT**[^4], **user mode**, **tap**, **bridge**), _redirections de ports_, _modÃ¨les Virtio_ ou _cartes Ã©mulÃ©es classiques_. QEMU offre un large choix permettant aussi bien de connecter rapidement une VM Ã  Internet que de construire un lab isolÃ©, segmentÃ© ou totalement autonome.
    
    !!! info "Le rÃ©seau est un des piliers de lâ€™orchestration dâ€™un environnement rÃ©aliste."

    **OPTIONS CARTE RÃ‰SEAU**

    ```bash
    # DÃ©finir une adresse MAC spÃ©cifique
    -device virtio-net-pci,netdev=net0,mac=52:54:00:12:34:56
    
    # Types de cartes rÃ©seau :
    # virtio-net-pci : meilleures performances (requiert drivers virtio)
    # e1000          : compatibilitÃ© Intel Gigabit
    # rtl8139        : compatibilitÃ© anciens systÃ¨mes
    ```

    **MODE USER (NAT[^4] simple, pas de configuration hÃ´te)**

    ```bash
    # RÃ©seau NAT par dÃ©faut (la VM accÃ¨de Ã  Internet, pas l'inverse)
    -netdev user,id=net0 -device virtio-net-pci,netdev=net0
    
    # NAT avec redirection de port (SSH accessible depuis l'hÃ´te)
    -netdev user,id=net0,hostfwd=tcp::2222-:22 \
    -device virtio-net-pci,netdev=net0
    
    # Multiples redirections de port
    -netdev user,id=net0,hostfwd=tcp::2222-:22,hostfwd=tcp::8080-:80 \
    -device virtio-net-pci,netdev=net0
    ```

    **MODE TAP/BRIDGE (performances production)**
    ```bash
    # PrÃ©requis : crÃ©er un bridge sur l'hÃ´te
    # sudo ip link add br0 type bridge
    # sudo ip link set br0 up
    # sudo ip link set eth0 master br0
    
    # Connexion au bridge (requiert sudo ou CAP_NET_ADMIN)
    -netdev tap,id=net0,br=br0,helper=/usr/lib/qemu/qemu-bridge-helper \
    -device virtio-net-pci,netdev=net0
    ```

=== "Options : Affichage"

    Les options dâ€™affichage dÃ©finissent la **maniÃ¨re dont la VM prÃ©sente une interface graphique** : __fenÃªtre locale__ (**GTK**, **SDL**), _accÃ¨s Ã  distance_ (**VNC**, **SPICE**), _mode console seul_, ou _fonctionnement totalement headless_.
    
    !!! info "Cette section permet dâ€™adapter la VM Ã  un usage poste de travail, serveur distant, lab isolÃ© ou environnement de test automatisÃ©."

    **Affichage Graphique**

    ```bash
    # Affichage GTK (fenÃªtre native Linux)
    -display gtk
    
    # Affichage SDL
    -display sdl
    
    # Serveur VNC (accÃ¨s distant)
    -display vnc=:0                  # Port 5900
    -display vnc=:1                  # Port 5901
    -display vnc=0.0.0.0:0           # Ã‰coute sur toutes les interfaces
    
    # Serveur SPICE (meilleur que VNC, supporte audio/USB)
    -spice port=5900,disable-ticketing=on
    
    # Sans affichage (serveur headless)
    -display none
    -nographic                       # Console sÃ©rie uniquement
    ```

    **Carte Graphique Virtuelle**

    Ces options dÃ©crivent la **carte vidÃ©o Ã©mulÃ©e** ou para-virtualisÃ©e par QEMU : ``std``, ``qxl``, ``virtio`` ou ``modÃ¨les historiques``. **Le choix du GPU virtuel influence** _la compatibilitÃ© avec lâ€™invitÃ©_, _la performance de lâ€™affichage_ et _lâ€™expÃ©rience utilisateur_, en particulier avec ``SPICE`` ou les environnements graphiques modernes.
    
    !!! info "**Virtio-GPU** est privilÃ©giÃ© pour ses performances, tandis que **QXL** reste pertinent pour les environnements **SPICE**."
    
    ```bash
    # VGA standard (compatibilitÃ©)
    -vga std
    
    # QXL (optimisÃ© pour SPICE)
    -vga qxl
    
    # Virtio-GPU (meilleures performances 3D)
    -vga virtio
    
    # Cirrus (legacy, trÃ¨s anciens systÃ¨mes)
    -vga cirrus
    ```

### **Options Firmware & Diverses**

=== "Options : Firmware"

    Ces options contrÃ´lent le **firmware utilisÃ© par la machine virtuelle**, câ€™est-Ã -dire la phase dâ€™amorÃ§age qui prÃ©cÃ¨de le chargement du systÃ¨me dâ€™exploitation. QEMU permet dâ€™utiliser un **BIOS classique** (SeaBIOS) ou un **firmware UEFI** (OVMF), indispensable pour Windows 11, les systÃ¨mes modernes, le Secure Boot ou les environnements plus proches du matÃ©riel rÃ©el.

    !!! info "Choisir le bon firmware influence la compatibilitÃ©, la structure des disques, les performances au boot et certaines fonctions avancÃ©es comme le TPM ou le passthrough matÃ©riel."

    ```bash
    # Utiliser le firmware BIOS SeaBIOS (mode hÃ©ritÃ©)
    -bios /usr/share/qemu/bios.bin

    # Utiliser le firmware UEFI OVMF (recommandÃ© pour Windows 10/11)
    -bios /usr/share/OVMF/OVMF_CODE.fd

    # Ajouter le fichier NVRAM (permet de sauvegarder les rÃ©glages UEFI)
    -drive if=pflash,format=raw,readonly=on,file=/usr/share/OVMF/OVMF_CODE.fd
    -drive if=pflash,format=raw,file=/var/lib/libvirt/qemu/nvram/win11_VARS.fd

    # UEFI avec Secure Boot (si ton OVMF le supporte)
    -bios /usr/share/OVMF/OVMF_CODE.secboot.fd
    ```

=== "Options : Diverses"

    Ces options regroupent les fonctionnalitÃ©s transverses qui ne sâ€™inscrivent pas dans une catÃ©gorie unique mais qui jouent un rÃ´le essentiel dans la **stabilitÃ©**, la **visibilitÃ©** et la **personnalisation** dâ€™une VM.
    
    On y retrouve **le nommage de la VM**, **la console sÃ©rie**, **le moniteur QEMU**, **les timers**, **la gestion des logs**, **le contrÃ´le du shutdown ACPI**, ou encore **les paramÃ¨tres influenÃ§ant la sÃ©curitÃ©** et la faÃ§on dont QEMU interagit avec lâ€™hÃ´te.
    
    !!! info "Ces rÃ©glages constituent la â€œboÃ®te Ã  outils gÃ©nÃ©raleâ€ permettant dâ€™adapter finement une VM Ã  un cas dâ€™usage particulier, quâ€™il sâ€™agisse de test, de production ou de lab cybersÃ©curitÃ©."

    ```bash
    # Nom interne de la VM
    -name "debian-test"

    # Horloge synchronisÃ©e sur lâ€™hÃ´te (important pour environnements sensibles au temps)
    -rtc base=localtime

    # Activer ACPI (arrÃªt propre depuis lâ€™hÃ´te)
    -acpi

    # Activer la pagination du moniteur QEMU (contrÃ´le interactif)
    -monitor stdio

    # Exposer le moniteur sur un socket (snapshots, debug, automation)
    -monitor telnet:127.0.0.1:55555,server,nowait

    # Console sÃ©rie (utile en mode serveur ou pour debug kernel)
    -serial stdio

    # Activer un logfile QEMU
    -D /var/log/qemu/debian.log

    # DÃ©sactiver les pÃ©riphÃ©riques par dÃ©faut (surface dâ€™attaque rÃ©duite)
    -nodefaults

    # Ajouter manuellement un clavier/souris para-virtualisÃ©s
    -device virtio-keyboard-pci
    -device virtio-mouse-pci
    ```

---

## Exemples d'utilisations

Cette derniÃ¨re partie propose une **sÃ©rie de recettes complÃ¨tes** montrant comment assembler les options vues prÃ©cÃ©demment dans des cas concrets : _ISO de test_, _VM Linux de base_, _Windows 11_, _Ã©mulation ARM_, _lab malware_.  

Chaque exemple est pensÃ© comme un **point de dÃ©part** : lâ€™objectif nâ€™est pas dâ€™Ãªtre exhaustif, mais de montrer une **structure de commande claire** que vous pourrez adapter Ã  votre contexte (_RAM_, _CPU_, _rÃ©seau_, _stockage_).


### Exemple minimal : Booter sur un ISO

Cet exemple montre la structure la plus simple **pour dÃ©marrer une machine virtuelle uniquement depuis une image ISO**. Il sert dâ€™introduction Ã  QEMU avant dâ€™ajouter le disque, le rÃ©seau, KVM ou les pÃ©riphÃ©riques virtuels.

```bash
# Exemple minimal : Booter sur un ISO
qemu-system-x86_64 \
  -cdrom debian-12.iso \       # Image ISO du CD-ROM
  -boot d \                    # Booter sur le CD (d = cdrom)
  -m 2048                      # 2 Go de RAM
```
<small><i>Cet exemple illustre le mode de dÃ©marrage le plus simple : un ISO, de la RAM, pas de disque. Utile pour tester des images live ou valider que QEMU fonctionne correctement.</i></small>

### VM Linux minimale avec KVM

Cet exemple montre la structure dâ€™une VM simple et performante en utilisant les options essentielles : machine ``q35``, CPU ``host``, _disque en Virtio_ et _NAT[^4] basique_. Câ€™est le modÃ¨le standard pour lancer rapidement une VM Linux moderne avec dâ€™excellentes performances.

```bash
#!/bin/bash
# VM Linux minimale avec KVM
# Usage : ./start-vm.sh

qemu-system-x86_64 \
  -name "debian-server" \
  -machine q35,accel=kvm \
  -cpu host \
  -smp 2 \
  -m 2G \
  -drive file=debian.qcow2,format=qcow2,if=virtio \
  -netdev user,id=net0,hostfwd=tcp::2222-:22 \
  -device virtio-net-pci,netdev=net0 \
  -display gtk
```
<small><i>Cette configuration illustre lâ€™usage minimal dâ€™une VM performante : **KVM activÃ©**, **CPU natif**, **disque Virtio** et **NAT** pour un accÃ¨s rapide Ã  la machine via **SSH**. Câ€™est la base de toutes les VMs Linux de test ou de dÃ©veloppement.</i></small>

**DÃ©cryptage rapide :**

* `-machine q35,accel=kvm` : machine moderne avec accÃ©lÃ©ration KVM.
* `-cpu host` : expose les fonctionnalitÃ©s CPU de lâ€™hÃ´te pour maximiser les performances.
* `-smp 2` : 2 vCPUs.
* `-m 2048` : 2 Go de RAM.
* `-drive ... if=virtio` : disque virtuel en Virtio (performant).
* `-netdev user,hostfwd=...` + `-device virtio-net-pci` : rÃ©seau NAT avec port 2222 â†’ 22 (SSH dans la VM depuis lâ€™hÃ´te).
* `-display gtk` : fenÃªtre graphique locale.

!!! warning "AprÃ¨s installation, tu pourras retirer `-cdrom` et passer en `-boot order=c` (disque)."

### VM Windows 11 avec UEFI

Cet exemple prÃ©sente la configuration complÃ¨te nÃ©cessaire **pour installer Windows 11** : _firmware UEFI_, _module TPM simulÃ©_, _Virtio pour le disque_ et _SPICE pour lâ€™affichage_. Câ€™est une configuration rÃ©aliste de machine Windows moderne sous QEMU/KVM.

```bash
#!/bin/bash
# VM Windows 11 avec UEFI et TPM Ã©mulÃ©

qemu-system-x86_64 \
  -name "windows11" \
  -machine q35,accel=kvm \
  -cpu host \
  -smp 4,cores=4 \
  -m 8G \
  \
  # Firmware UEFI (requis pour Windows 11)
  -bios /usr/share/OVMF/OVMF_CODE.fd \
  \
  # TPM Ã©mulÃ© (requis pour Windows 11)
  -chardev socket,id=chrtpm,path=/tmp/swtpm.sock \
  -tpmdev emulator,id=tpm0,chardev=chrtpm \
  -device tpm-tis,tpmdev=tpm0 \
  \
  # Disque systÃ¨me
  -drive file=windows11.qcow2,format=qcow2,if=virtio \
  \
  # ISO d'installation et drivers VirtIO
  -drive file=Win11.iso,media=cdrom \
  -drive file=virtio-win.iso,media=cdrom \
  \
  # RÃ©seau
  -netdev user,id=net0 \
  -device virtio-net-pci,netdev=net0 \
  \
  # Affichage haute performance
  -vga qxl \
  -display spice-app
```
<small><i>Cet exemple illustre les prÃ©requis stricts de Windows 11 : UEFI, TPM 2.0, stockage Virtio et un affichage SPICE performant.</i></small>

### Booter sur un ISO Debian en QEMU/KVM

Ce modÃ¨le est conÃ§u pour **une installation Debian complÃ¨te**. Il combine _lâ€™accÃ©lÃ©ration KVM_, _un disque qcow2 performant_, _un accÃ¨s SSH_ via _NAT[^4]_ et _une interface graphique locale_. Câ€™est la recette classique pour installer une distribution depuis lâ€™ISO.

```bash
# Exemple : booter sur un ISO Debian en QEMU/KVM

qemu-system-x86_64 \
  -name "debian-install" \
  -machine q35,accel=kvm \
  -cpu host \
  -smp 2 \
  -m 2048 \
  -drive file=debian.qcow2,format=qcow2,if=virtio \
  -cdrom debian-12.iso \
  -boot order=d \
  -netdev user,id=net0,hostfwd=tcp::2222-:22 \
  -device virtio-net-pci,netdev=net0 \
  -display gtk
```
<small><i>Cet exemple montre comment installer proprement une distribution Linux : ISO en prioritÃ©, disque Virtio et accÃ¨s SSH immÃ©diatement disponible.</i></small>

### Ã‰mulation ARM (Raspberry Pi)

Cet exemple dÃ©montre comment utiliser QEMU pour **Ã©muler un environnement ARM 64 bits**, comme un **Raspberry Pi**. Il est utile pour tester des firmwares, dÃ©velopper pour ARM ou simuler des environnements IoT.

```bash
#!/bin/bash
# Ã‰mulation Raspberry Pi 3 (ARM64)

qemu-system-aarch64 \
  -name "raspi3" \
  -machine raspi3b \
  -cpu cortex-a72 \
  -m 1G \
  \
  # Image Raspberry Pi OS
  -drive file=raspios.img,format=raw,if=sd \
  \
  # Console sÃ©rie (pas d'affichage graphique natif)
  -serial stdio \
  -display none \
  \
  # Kernel et device tree externes (si nÃ©cessaire)
  # -kernel kernel8.img \
  # -dtb bcm2710-rpi-3-b.dtb \
  # -append "console=ttyAMA0 root=/dev/mmcblk0p2 rootwait"
```
<small><i>Cet exemple illustre lâ€™usage de QEMU comme Ã©mulateur multi-architecture : idÃ©al pour tester des OS ARM sans matÃ©riel physique.</i></small>

### Lab de sÃ©curitÃ© isolÃ©

Cet exemple illustre la crÃ©ation dâ€™un environnement **dâ€™analyse de malware totalement isolÃ© du rÃ©seau rÃ©el**, avec un **overlay non-persistant** et un **moniteur QEMU** ouvert pour **les manipulations forensic**.

```bash
#!/bin/bash
# VM pour analyse de malware (rÃ©seau isolÃ©)

qemu-system-x86_64 \
  -name "malware-analysis" \
  -machine q35,accel=kvm \
  -cpu host \
  -smp 2 \
  -m 4G \
  \
  # Snapshot-friendly : toujours dÃ©marrer depuis un Ã©tat propre
  -drive file=analysis.qcow2,format=qcow2,if=virtio,snapshot=on \
  \
  # RÃ©seau ISOLÃ‰ (aucune connexion externe)
  -netdev user,id=net0,restrict=on \
  -device virtio-net-pci,netdev=net0 \
  \
  # Pas de pÃ©riphÃ©riques USB/audio (surface d'attaque rÃ©duite)
  -nodefaults \
  \
  # Moniteur QEMU pour contrÃ´le (snapshots, inspection)
  -monitor stdio \
  \
  -display gtk
```

<small><i>Cet exemple montre comment crÃ©er un environnement **sÃ©curisÃ©** et **non persistant**, essentiel pour lâ€™analyse de malware : overlay, rÃ©seau restreint et moniteur QEMU ouvert pour lâ€™introspection mÃ©moire.</i></small>

---

## En rÃ©sumÃ© pour la production KVM

!!! note "Configuration type Ã  viser pour une VM Linux de prod"
Pour une VM Linux â€œclassiqueâ€ avec QEMU/KVM, nous devons viser en prioritÃ© :

- Machine : `-machine q35,accel=kvm`
- CPU : `-cpu host` avec `-smp` adaptÃ© Ã  la charge
- MÃ©moire : `-m 4G` (ou plus) avec Ã©ventuellement des **huge pages**[^3] pour les grosses charges mÃ©moire
- Disque : image **qcow2**, Virtio, `cache=none,aio=native` pour de bonnes performances I/O
- RÃ©seau : Virtio (`virtio-net-pci`), NAT[^4] ou bridge selon le besoin
- Gestion : dÃ¨s que possible, passe la gestion quotidienne sous **libvirt/virsh** ou **Proxmox/virt-manager**, plutÃ´t que dâ€™empiler des lignes QEMU Ã  la main

---

## Le mot de la fin

!!! quote
    QEMU incarne la **flexibilitÃ© ultime** de la virtualisation open-source. En maÃ®trisant QEMU, vous ne dÃ©pendez plus d'interfaces graphiques limitÃ©es ou de solutions propriÃ©taires : vous contrÃ´lez chaque aspect de vos machines virtuelles, du firmware au rÃ©seau, du CPU Ã  l'Ã©mulation d'architectures exotiques.
    
    Pour un professionnel de la cybersÃ©curitÃ©, QEMU ouvre des possibilitÃ©s uniques : **analyse de malware** dans des environnements parfaitement isolÃ©s et jetables, **Ã©mulation de firmwares IoT** pour dÃ©couvrir des vulnÃ©rabilitÃ©s, **laboratoires de pentest** reproductibles et scriptables. La capacitÃ© de prendre des **snapshots** Ã  tout moment, d'**introspecter la mÃ©moire** d'une VM, ou de **simuler des architectures ARM/MIPS** sur un simple PC x86 fait de QEMU un outil indispensable.
    
    CombinÃ© Ã  **KVM**, QEMU offre des performances proches du bare-metal, rivalisant avec les solutions commerciales. IntÃ©grÃ© Ã  **libvirt** et **Proxmox**, il devient la base d'infrastructures de production robustes. UtilisÃ© en mode Ã©mulation pure, il permet le dÃ©veloppement cross-plateforme et l'analyse de systÃ¨mes embarquÃ©s.
    
    > **MaÃ®triser QEMU, c'est comprendre les fondations sur lesquelles repose toute la virtualisation Linux moderne, et disposer d'un couteau suisse inÃ©galÃ© pour l'analyse, le dÃ©veloppement et les tests de sÃ©curitÃ©.**

---

## Ressources complÃ©mentaires

### Documentation officielle

- **QEMU Documentation** : [https://www.qemu.org/docs/master/](https://www.qemu.org/docs/master/)
- **QEMU Wiki** : [https://wiki.qemu.org/](https://wiki.qemu.org/)
- **libvirt Documentation** : [https://libvirt.org/docs.html](https://libvirt.org/docs.html)

### Guides spÃ©cialisÃ©s

- **Arch Wiki - QEMU** : [https://wiki.archlinux.org/title/QEMU](https://wiki.archlinux.org/title/QEMU)
- **Debian Wiki - QEMU** : [https://wiki.debian.org/QEMU](https://wiki.debian.org/QEMU)
- **Red Hat Virtualization Guide** : [https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/configuring_and_managing_virtualization/](https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/configuring_and_managing_virtualization/)

### Outils associÃ©s

- **Proxmox VE** : [https://www.proxmox.com/](https://www.proxmox.com/)
- **virt-manager** : [https://virt-manager.org/](https://virt-manager.org/)
- **VirtIO Drivers Windows** : [https://github.com/virtio-win/virtio-win-pkg-scripts](https://github.com/virtio-win/virtio-win-pkg-scripts)

### SÃ©curitÃ© et analyse

- **QEMU/KVM Hardening** : [https://wiki.qemu.org/Features/VirtIOSerial](https://wiki.qemu.org/Features/VirtIOSerial)
- **Malware Analysis with QEMU** : Practical Malware Analysis (livre de rÃ©fÃ©rence)
- **Firmware Analysis** : [https://github.com/firmadyne/firmadyne](https://github.com/firmadyne/firmadyne)


[^1]: **KVM** (*Kernel-based Virtual Machine*) est une technologie de virtualisation intÃ©grÃ©e directement au noyau Linux, qui transforme le systÃ¨me en hyperviseur capable dâ€™exÃ©cuter des machines virtuelles avec des performances proches du bare-metal grÃ¢ce au support matÃ©riel (VT-x/AMD-V).

[^2]: **VT-x / AMD-V** : extensions de virtualisation matÃ©rielle des CPU Intel/AMD qui permettent dâ€™exÃ©cuter du code invitÃ© en mode â€œvirtualisationâ€ plutÃ´t quâ€™en pure Ã©mulation.

[^3]: Les **huge pages** sont des pages mÃ©moire plus grandes (par exemple 2 Mo au lieu de 4 Ko). Elles rÃ©duisent le travail de la MMU et peuvent amÃ©liorer les performances, notamment pour des VMs trÃ¨s gourmandes en RAM.

[^4]: En mode **NAT**, la VM sort vers Internet via lâ€™hÃ´te, mais nâ€™est pas directement joignable depuis le rÃ©seau. Un **bridge** la place sur le mÃªme plan que les autres machines du LAN.

[^5]: Un hyperviseur de type 1 sâ€™exÃ©cute â€œau plus prÃ¨s du matÃ©rielâ€ (ou intÃ©grÃ© au noyau), contrairement Ã  un hyperviseur de type 2 qui tourne comme un programme utilisateur sur un OS existant.
[^6]: **thin provisioning** : allocation paresseuse de lâ€™espace disque, seule la partie rÃ©ellement utilisÃ©e est occupÃ©e sur le stockage.
[^7]: Dans QEMU, un **backing file** est lâ€™image disque Â« parent Â» sur laquelle une image *overlay* sâ€™appuie pour ne stocker que les modifications, ce qui permet de crÃ©er plusieurs machines virtuelles dÃ©rivÃ©es dâ€™une mÃªme base sans dupliquer tout le disque.
